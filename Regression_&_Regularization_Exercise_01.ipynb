{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chEqqJbLzFew"
      },
      "source": [
        "# Ydata Data Science School\n",
        "## Linear Regression & Regularization Exercise.\n",
        "\n",
        "\n",
        "## Outline\n",
        "In this exercise you will learn the following topics:\n",
        "\n",
        "1. Refresher on how linear regression is solved in batch and in Gradient Descent\n",
        "2. Implementation of Ridge Regression\n",
        "3. Comparing Ridge, Lasso and vanila Linear Regression on a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR9UFmk2greT"
      },
      "source": [
        "## Refresher on Ordinary Least Square (OLS) aka Linear Regeression\n",
        "\n",
        "### Lecture Note\n",
        "\n",
        "In Matrix notation, the matrix $X$ is of dimensions $n \\times p$ where each row is an example and each column is a feature dimension.\n",
        "\n",
        "Similarily, $y$ is of dimension $n \\times 1$ and $w$ is of dimensions $p \\times 1$.\n",
        "\n",
        "The model is $\\hat{y}=X\\cdot w$ where we assume for simplicity that $X$'s first columns equals to 1 (one padding), to account for the bias term.\n",
        "\n",
        "Our objective is to optimize the loss $L$ defines as resiudal sum of squares (RSS):\n",
        "\n",
        "$L_{RSS}=\\frac{1}{N}\\left\\Vert Xw-y \\right\\Vert^2$ (notice that in matrix notation this means summing over all examples, so $L$ is scalar.)\n",
        "\n",
        "To find the optimal $w$ one needs to derive the loss with respect to $w$.\n",
        "\n",
        "$\\frac{\\partial{L_{RSS}}}{\\partial{w}}=\\frac{2}{N}X^T(Xw-y)$ (to see why, read about [matrix derivatives](http://www.gatsby.ucl.ac.uk/teaching/courses/sntn/sntn-2017/resources/Matrix_derivatives_cribsheet.pdf) or see class notes )\n",
        "\n",
        "Thus, the gardient descent solution is $w'=w-\\alpha \\frac{2}{N}X^T(Xw-y)$.\n",
        "\n",
        "Solving $\\frac{\\partial{L_{RSS}}}{\\partial{w}}=0$ for $w$ one can also get analytical solution:\n",
        "\n",
        "$w_{OLS}=(X^TX)^{-1}X^Ty$\n",
        "\n",
        "The first term, $(X^TX)^{-1}X^T$ is also called the pseudo inverse of $X$.\n",
        "\n",
        "See [lecture note from Stanford](https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_NYU_notes.pdf) for more details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA3MEKz80vdy"
      },
      "source": [
        "## Exercise 1 - Ordinary Least Square\n",
        "* Get the boston housing dataset https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n",
        "\n",
        "* What is $p$? what is $n$ in the above notation? hint: [shape](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.ndarray.shape.html)\n",
        "\n",
        "* write a model `OrdinaryLinearRegression` which has a propoery $w$ and 3 methods: `fit`, `predict` and `score` (which returns the MSE on a given sample set). Hint: use [numpy.linalg.pinv](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.linalg.pinv.html) to be more efficient.\n",
        "\n",
        "* Fit the model. What is the training MSE?\n",
        "\n",
        "* Plot a scatter plot where on x-axis plot $Y$ and in the y-axis $\\hat{Y}_{OLS}$\n",
        "\n",
        "* Split the data to 75% train and 25% test 20 times. What is the average MSE now for train and test? Hint: use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) or [ShuffleSplit](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html).\n",
        "\n",
        "* Use a t-test to proove that the MSE for training is significantly smaller than for testing. What is the p-value? Hint: use [scipy.stats.ttest_rel](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ttest_rel.html).\n",
        "\n",
        "* Write a new class `OrdinaryLinearRegressionGradientDescent` which inherits from `OrdinaryLinearRegression` and solves the problem using gradinet descent. The class should get as a parameter the learning rate and number of iteration. Plot the class convergance. What is the effect of learning rate? How would you find number of iteration automatically? Note: Gradient Descent does not work well when features are not scaled evenly (why?!). Be sure to normalize your features first.\n",
        "\n",
        "* The following parameters are optional (not mandatory to use):\n",
        "    * early_stop - True / False boolean to indicate to stop running when loss stops decaying and False to continue.\n",
        "    * verbose- True/False boolean to turn on / off logging, e.g. print details like iteration number and loss (https://en.wikipedia.org/wiki/Verbose_mode)\n",
        "    * track_loss - True / False boolean when to save loss results to present later in learning curve graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZuSS8LhcfZdn"
      },
      "outputs": [],
      "source": [
        "# * write a model `Ols` which has a propoery $w$ and 3 methods: `fit`, `predict` and `score`.? hint: use [numpy.linalg.pinv](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.linalg.pinv.html) to be more efficient.\n",
        "import numpy as np\n",
        "class Ols(object):\n",
        "  def __init__(self):\n",
        "    self.w = None\n",
        "\n",
        "  @staticmethod\n",
        "  def pad(X):\n",
        "    pass\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    #remeber pad with 1 before fitting\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "    self.w = (np.linalg.pinv(X.T@X))@X.T@Y\n",
        "\n",
        "\n",
        "  def _fit(self, X, Y):\n",
        "    # optional to use this\n",
        "    pass\n",
        "\n",
        "  def predict(self, X):\n",
        "    #return wx\n",
        "    w = self.w\n",
        "    #w = w[:,None]\n",
        "    w = np.expand_dims(w,axis=-1)\n",
        "    return X@w\n",
        "\n",
        "  def _predict(self, X):\n",
        "    # optional to use this\n",
        "    pass\n",
        "\n",
        "  def score(self, X, Y):\n",
        "    #return MSE\n",
        "    #w = self.w[:,np.newaxis]\n",
        "    w = self.w\n",
        "    #w = w[:,None]\n",
        "    w = np.expand_dims(w,axis=-1)\n",
        "    return np.sum((X@w-Y)**2)[0]/Y.size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "np.random.seed(42)\n",
        "data = pd.read_csv('/content/Boston-house-price-data.csv')\n",
        "data.head()\n",
        "X = data.iloc[:,:-1]\n",
        "Y = data.iloc[:,-1]"
      ],
      "metadata": {
        "id": "hx3ar6H7N0uW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "model = Ols();\n",
        "model.fit(X_train,Y_train);\n",
        "model.predict(X_test);\n",
        "model.score(X_train,Y_train);\n",
        "model.score(X_test,Y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvPmt-zjPSgq",
        "outputId": "bdb379aa-4a16-41eb-a62a-62db28b627f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73.28042565487205"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(Y_test, model.predict(X_test));\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "O4eS4JUVdeEn",
        "outputId": "edc94471-bca3-4982-b19e-ad4ed5f3af62"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_train = []\n",
        "mse_test = []\n",
        "for i in range(20):\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)\n",
        "  model = Ols();\n",
        "  model.fit(X_train,Y_train);\n",
        "  model.predict(X_test);\n",
        "  mse_train.append(model.score(X_train,Y_train))\n",
        "  mse_test.append(model.score(X_test,Y_test))\n",
        "\n",
        "mse_test,mse_train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP2LKhKkeXPR",
        "outputId": "5a08c711-145b-49d5-d0a4-4a065aa464be"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([75.66791446930783,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  75.5320325471092,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  68.62895573868218,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  57.3971974292682,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  67.50807591510454,\n",
              "  65.81225010060511,\n",
              "  67.50126343122886,\n",
              "  68.78546089709477,\n",
              "  0.0,\n",
              "  68.41900797598498,\n",
              "  65.0656558564397,\n",
              "  63.32496939847582,\n",
              "  62.368632307752506,\n",
              "  62.74919526601235,\n",
              "  0.0,\n",
              "  61.35768616298889,\n",
              "  65.97859701410773,\n",
              "  64.18719422806102,\n",
              "  63.51956800469107,\n",
              "  60.2222362291116,\n",
              "  61.25771952935267,\n",
              "  0.0,\n",
              "  69.53851401111271])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "stats.ttest_rel(mse_train, mse_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyGF5ldIgWzL",
        "outputId": "c33c5a46-ed91-4907-f845-7960df85f5aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=3.0788341292836856, pvalue=0.0061797062557292564, df=19)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "B689kXfa1eit"
      },
      "outputs": [],
      "source": [
        "# Write a new class OlsGd which solves the problem using gradinet descent.\n",
        "# The class should get as a parameter the learning rate and number of iteration.\n",
        "# Plot the loss convergance. for each alpha, learning rate plot the MSE with respect to number of iterations.\n",
        "# What is the effect of learning rate?\n",
        "# How would you find number of iteration automatically?\n",
        "# Note: Gradient Descent does not work well when features are not scaled evenly (why?!). Be sure to normalize your feature first.\n",
        "class Normalizer():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def fit(self, X):\n",
        "    self.X_min = X.T.min(axis=1)\n",
        "    self.X_max = X.T.max(axis=1)\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    #apply normalization\n",
        "    return (X-self.X_min)/(self.X_max - self.X_min)\n",
        "\n",
        "class OlsGd(Ols):\n",
        "\n",
        "  def __init__(self, learning_rate=.05,\n",
        "               num_iteration=1000,\n",
        "               normalize=True,\n",
        "               early_stop=True,\n",
        "               verbose=True):\n",
        "\n",
        "    super(OlsGd, self).__init__()\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iteration = num_iteration\n",
        "    self.early_stop = early_stop\n",
        "    self.normalize = normalize\n",
        "    self.normalizer = Normalizer()\n",
        "    self.verbose = verbose\n",
        "\n",
        "  def _fit(self, X, Y, reset=True, track_loss=True):\n",
        "    #remeber to normalize the data before starting\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "    norm = Normalizer()\n",
        "    norm.fit(X)\n",
        "    X = norm.predict(X)\n",
        "    num_iter=0\n",
        "    w = np.ones(X.shape[1])\n",
        "    for i in range(self.num_iteration):\n",
        "      L_gradient = -2 * (X.T@X@w - X.T@Y)\n",
        "      w = w - (self.learning_rate * L_gradient)\n",
        "    self.w = w\n",
        "\n",
        "  def _predict(self, X):\n",
        "    #remeber to normalize the data before starting\n",
        "    norm = Normalizer()\n",
        "    norm.fit(self.X)\n",
        "    X = norm.predict(X)\n",
        "    w = self.w\n",
        "    w = np.expand_dims(w,axis=-1)\n",
        "    return X@w\n",
        "\n",
        "  def _step(self, X, Y):\n",
        "    # use w update for gradient descent\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_train = []\n",
        "mse_test = []\n",
        "for i in range(20):\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)\n",
        "  model = OlsGd(learning_rate=.05, num_iteration=2000);\n",
        "  model.fit(X_train,Y_train);\n",
        "  model.predict(X_test);\n",
        "  mse_train.append(model.score(X_train,Y_train))\n",
        "  mse_test.append(model.score(X_test,Y_test))\n",
        "\n",
        "mse_test,mse_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkHwrVH_8Up2",
        "outputId": "ab785ad0-d719-485b-d32d-b02ac36d0cc6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  56.48683087790454,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  70.21108254484984,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  79.45176157911237,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [63.68405892573148,\n",
              "  59.35879592495782,\n",
              "  63.32585508274068,\n",
              "  0.0,\n",
              "  65.98394950140782,\n",
              "  67.6187522769557,\n",
              "  63.88848149267743,\n",
              "  71.43196465622063,\n",
              "  67.65468329420494,\n",
              "  66.47402533906596,\n",
              "  61.73310404029266,\n",
              "  0.0,\n",
              "  64.02424773976158,\n",
              "  65.58462560815931,\n",
              "  66.58862417922568,\n",
              "  0.0,\n",
              "  59.07869864172104,\n",
              "  66.34661683390088,\n",
              "  60.506545225618275,\n",
              "  64.12069811513582])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm = Normalizer()\n",
        "#norm.predict(X_test)"
      ],
      "metadata": {
        "id": "JBYlHTRjodA9"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HVfnXvZFi98"
      },
      "source": [
        "## Exercise 2 - Ridge Linear Regression\n",
        "\n",
        "Recall that ridge regression is identical to OLS but with a L2 penalty over the weights:\n",
        "\n",
        "$L(y,\\hat{y})=\\sum_{i=1}^{i=N}{(y^{(i)}-\\hat{y}^{(i)})^2} + \\lambda \\left\\Vert w \\right\\Vert_2^2$\n",
        "\n",
        "where $y^{(i)}$ is the **true** value and $\\hat{y}^{(i)}$ is the **predicted** value of the $i_{th}$ example, and $N$ is the number of examples\n",
        "\n",
        "* Show, by differentiating the above loss, that the analytical solution is $w_{Ridge}=(X^TX+\\lambda I)^{-1}X^Ty$\n",
        "* Change `OrdinaryLinearRegression` and `OrdinaryLinearRegressionGradientDescent` classes to work also for ridge regression. Either add a parameter, or use inheritance.\n",
        "* **Bonus: Noise as a regularizer**: Show that OLS (ordinary least square), if one adds multiplicative noise to the features the **average** solution for $W$ is equivalent to Ridge regression. In other words, if $X'= X*G$ where $G$ is an uncorrelated noise with variance $\\sigma$ and mean 1, then solving for $X'$ with OLS is like solving Ridge for $X$. What is the interpretation?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$L = (Xw - y)^T(Xw - y) + λw^Tw → min$\n",
        "\n",
        "$∇_w L = X^T(Xw-y) + (Xw-y)^TX + λ(I^Tw + w^TI) = X^TXw-X^Ty + X^T(Xw-y) +λ(I^Tw+I^Tw) =$\n",
        "$= 2X^TXw-2X^Ty+2λI^Tw = 0$\n",
        "\n",
        "$(X^TX+λI^T)w = X^Ty$\n",
        "\n",
        "$w = (X^TX + λI^T)^{-1}X^Ty$\n",
        "\n",
        "$w = (X^TX + λI)^{-1}X^Ty$"
      ],
      "metadata": {
        "id": "joivmdaAFqc6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4v0foNX1eiu"
      },
      "outputs": [],
      "source": [
        "class RidgeLs(Ols):\n",
        "  def __init__(self, ridge_lambda, *wargs, **kwargs):\n",
        "    super(RidgeLs,self).__init__(*wargs, **kwargs)\n",
        "    self.ridge_lambda = ridge_lambda\n",
        "\n",
        "  def _fit(self, X, Y):\n",
        "    #Closed form of ridge regression\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAj1Qxoc1eiu"
      },
      "source": [
        "### Use scikitlearn implementation for OLS, Ridge and Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GozQEKRw1eiu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}